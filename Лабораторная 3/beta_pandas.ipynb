{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df1a682-3370-4fc7-9195-3a0aae985d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in c:\\users\\night\\anaconda3\\lib\\site-packages (0.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83caa238-ffe7-45a8-85c0-20e0bc02b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44c32e9-abe8-4d38-a0bb-67f9b02d6a7d",
   "metadata": {},
   "source": [
    "# Обнуление словарей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "580efeec-62eb-42bb-beb9-5279e2e84d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_files = {}\n",
    "saved_tables = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd65e4-d42e-42c7-ad6b-493a563260c6",
   "metadata": {},
   "source": [
    "## Тест для .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a1537928-5d17-44a9-b98d-be424a96f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['ID', 'USER', 'PASS'], ['1', 'IVAN', 'jhsfuga612'], ['2', 'KOSTYA', 'EFSFGfj145nb'], ['3', 'ARTEM', 'JHFIGAghHFJ6351']]\n",
    "with open('pikle.pkl', 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec68084c-35cf-405d-8d0a-c19e1a35922f",
   "metadata": {},
   "source": [
    "## Тест для .csv (у меня работает с delimiter'ом через ',', но если слипляет в 1 ячейку, то заменить на ';')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "aebe1c01-2503-442b-a5d2-3ef014c04d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['ID', 'USER', 'PASS'], ['1', 'IVAN', 'jhsfuga612'], ['2', 'KOSTYA', 'EFSFGfj145nb'], ['3', 'ARTEM', 'JHFIGAghHFJ6351']]\n",
    "\n",
    "with open('test.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ce80f0-f7a2-43d1-af57-2182fa66ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_name_extension_checker(file):\n",
    "    file_path = os.path.basename(file)\n",
    "    split_path = os.path.splitext(file_path)\n",
    "    if split_path[-1] == '.txt':\n",
    "        return (split_path[0], 'txt')\n",
    "    elif split_path[-1] == '.pkl':\n",
    "        return (split_path[0], 'pkl')\n",
    "    elif split_path[-1] == '.csv':\n",
    "        return (split_path[0], 'csv')\n",
    "    else:\n",
    "        return (split_path[0], 'The type of your file is not suitable.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18542997-483f-42ab-9780-a8773a4365c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def types_getter(data_list, types_list):\n",
    "    for i in range(len(data_list)):\n",
    "        i_type_list = []\n",
    "        for j in range(len(data_list[i])):\n",
    "            el = data_list[i][j]\n",
    "            if el != None:\n",
    "                if el.isdigit() == True:\n",
    "                    i_type_list.append(type(100))\n",
    "                else:\n",
    "                    if '.' in el:\n",
    "                        el = el.replace('.', '')\n",
    "                        if el.isdigit() == True:\n",
    "                            i_type_list.append(type(1.0))\n",
    "                        else:    \n",
    "                            i_type_list.append(type(el))\n",
    "                                \n",
    "                    elif ',' in el:\n",
    "                        el = el.replace(',', '')\n",
    "                        if el.isdigit() == True:\n",
    "                            i_type_list.append(type(1.0))\n",
    "                        else:\n",
    "                            i_type_list.append(type(el))\n",
    "    \n",
    "                    elif el.lower() == 'true' or el.lower() == 'false':\n",
    "                        i_type_list.append(type(True))\n",
    "    \n",
    "                    else:\n",
    "                        i_type_list.append(type(el))\n",
    "            else:\n",
    "                i_type_list.append(type(el))\n",
    "                                    \n",
    "        types_list.append(i_type_list)\n",
    "\n",
    "    return types_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "72da048b-b08b-4180-8613-f503b793099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def None_csv_pikle_setter(start_list, headers):\n",
    "    data_list = []\n",
    "    for i in range(len(start_list)):\n",
    "        splitted_line = start_list[i]\n",
    "        if '' in splitted_line:\n",
    "            while '' in splitted_line:\n",
    "                index = splitted_line.index('')\n",
    "                splitted_line[index] = None\n",
    "                data_list.append(splitted_line)\n",
    "        else:\n",
    "            if len(splitted_line) < len(headers):\n",
    "                diff = len(headers) - len(splitted_line)\n",
    "                splitted_line.append('None')\n",
    "                if diff != 1:\n",
    "                    for i in range(diff-1):\n",
    "                        splitted_line.append('None')\n",
    "                for j in range(len(splitted_line)):\n",
    "                    if splitted_line[j] == 'None':\n",
    "                        splitted_line[j] = None\n",
    "                data_list.append(splitted_line)\n",
    "                                \n",
    "            else:\n",
    "                data_list.append(splitted_line)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "94163fea-7dda-4422-b756-8cda07bc4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table(*file):\n",
    "    files = list(file)\n",
    "\n",
    "    for file in files:\n",
    "        file_name, ext = file_name_extension_checker(file=file)\n",
    "        data_list = []\n",
    "        types_list = []\n",
    "        if ext == 'txt':\n",
    "            with open(file, 'r', encoding='UTF-8') as file:\n",
    "                headers = file.readline().strip().split(' ')\n",
    "                line = file.readline().strip()\n",
    "                while line:\n",
    "                    splitted_line = line.split(' ')\n",
    "                    while '' in splitted_line:\n",
    "                        index = splitted_line.index('')\n",
    "                        splitted_line[index] = None\n",
    "                        data_list.append(splitted_line)\n",
    "                    \n",
    "                    if len(splitted_line) < len(headers):\n",
    "                        diff = len(headers) - len(splitted_line)\n",
    "                        splitted_line.append('None')\n",
    "                        if diff != 1:\n",
    "                            for i in range(diff-1):\n",
    "                                splitted_line.append('None')\n",
    "                        for j in range(len(splitted_line)):\n",
    "                            if splitted_line[j] == 'None':\n",
    "                                splitted_line[j] = None\n",
    "                        data_list.append(splitted_line)\n",
    "                        \n",
    "                    else:\n",
    "                        data_list.append(splitted_line)\n",
    "                    \n",
    "                    line = file.readline().strip()\n",
    "                \n",
    "                types_list = types_getter(data_list, types_list)\n",
    "                \n",
    "                headers_data_dict = {'headers': headers, 'data': data_list, 'types': types_list}\n",
    "                new_data = {file_name: headers_data_dict}\n",
    "            loaded_files.update(new_data)\n",
    "            \n",
    "                \n",
    "        elif ext == 'pkl':\n",
    "            with open(file, 'rb') as file:\n",
    "                data = pickle.load(file)\n",
    "\n",
    "            if type(data) == dict:\n",
    "                data_list = None_csv_pikle_setter(data['data'], data['headers'])\n",
    "                headers_data_dict = {'headers': data['headers'], 'data': data_list}\n",
    "\n",
    "            else:\n",
    "                types_list = []\n",
    "                headers = data[0]\n",
    "                data_list = data[1:]\n",
    "                \n",
    "                data_list = None_csv_pikle_setter(data_list, headers)\n",
    "                \n",
    "                types_list = types_getter(data_list, types_list)\n",
    "                \n",
    "                headers_data_dict = {'headers': headers, 'data': data_list, 'types': types_list}\n",
    "\n",
    "            new_data = {file_name: headers_data_dict}\n",
    "            loaded_files.update(new_data)\n",
    "    \n",
    "        \n",
    "        elif ext == 'csv':\n",
    "            with open(file, 'r', newline='', encoding='UTF-8') as file:\n",
    "                reader = list(csv.reader(file))\n",
    "\n",
    "            types_list = []\n",
    "            headers = reader[0]\n",
    "            data_list = reader[1:]\n",
    "            \n",
    "            data_list = None_csv_pikle_setter(data_list, headers)\n",
    "            \n",
    "            types_list = types_getter(data_list, types_list)\n",
    "                    \n",
    "            headers_data_dict = {'headers': headers, 'data': data_list, 'types': types_list}\n",
    "                \n",
    "            new_data = {file_name: headers_data_dict}\n",
    "            loaded_files.update(new_data)\n",
    "    \n",
    "                \n",
    "        elif ext == 'The type of your file is not suitable.':\n",
    "            return ext\n",
    "\n",
    "    return loaded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84b622e8-cc35-4dc8-9105-f1eb20b24c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': {'headers': ['ID', 'Name', 'City', 'Age'],\n",
       "  'data': [['1', 'Vlad', 'Moscow', '37'],\n",
       "   ['2', 'David', 'Tel-Aviv', '52'],\n",
       "   ['3', 'Jack', 'NewYork', '24']],\n",
       "  'types': [[int, str, str, int], [int, str, str, int], [int, str, str, int]]},\n",
       " 'text1': {'headers': ['ID', 'Name', 'City', 'Age'],\n",
       "  'data': [['1', 'John', 'Tomsk', '20'],\n",
       "   ['2', 'Sophie', 'Washington', '15'],\n",
       "   ['3', 'George', 'Tbilisi', '30'],\n",
       "   ['4', 'Ruslan', 'Erevan', '18'],\n",
       "   ['5', 'Emin', 'Baku', '32'],\n",
       "   ['6', 'Damir', 'Kazan', '19']],\n",
       "  'types': [[int, str, str, int],\n",
       "   [int, str, str, int],\n",
       "   [int, str, str, int],\n",
       "   [int, str, str, int],\n",
       "   [int, str, str, int],\n",
       "   [int, str, str, int]]}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_table('text.txt', 'text1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b76b2c2-d670-4b7d-87c0-1929c6a453a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table(loaded_files=loaded_files, file=None, max_rows=None) -> dict:\n",
    "    if max_rows == None:\n",
    "        saved_tables.update(loaded_files)\n",
    "    else:\n",
    "        file_name, ext = file_name_extension_checker(file=file)\n",
    "        if max_rows >= len(loaded_files[file_name]['data']):\n",
    "            saved_tables.update(loaded_files)\n",
    "        else:\n",
    "            files_num = len(loaded_files[file_name]['data']) // max_rows\n",
    "            if len(loaded_files[file_name]['data']) % max_rows != 0:\n",
    "                files_num += 1\n",
    "\n",
    "            start = 0\n",
    "            for file in range(files_num):\n",
    "                end = min(max_rows + start, len(loaded_files[file_name]['data']))\n",
    "                new_data = []\n",
    "                new_data = [loaded_files[file_name]['headers']]\n",
    "                if start != end:\n",
    "                    new_data.extend(loaded_files[file_name]['data'][start:end])\n",
    "                else:\n",
    "                    new_data.extend(loaded_files[file_name]['data'][start])\n",
    "    \n",
    "                new_file = f'{file+1}_{file_name}.{ext}'\n",
    "    \n",
    "                if ext == 'txt':\n",
    "                    with open(new_file, 'w', encoding='UTF-8') as file:\n",
    "                        for line in new_data:\n",
    "                            file.write(' '.join(str(word) for word in line) + '\\n')\n",
    "    \n",
    "                elif ext == 'pkl':\n",
    "                    with open(new_file, 'wb') as file:\n",
    "                        pickle.dump(new_data, file)\n",
    "    \n",
    "                elif ext == 'csv':\n",
    "                    with open(new_file, 'w', newline='', encoding='UTF-8') as file:\n",
    "                        writer = csv.writer(file, delimiter=',')\n",
    "                        writer.writerows(new_data)\n",
    "                        \n",
    "                start = end\n",
    "            \n",
    "    return saved_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5239e99-6665-4670-a26a-cc9130627300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': {'headers': ['ID', 'Name', 'City', 'Age'],\n",
       "  'data': [['1', 'Vlad', 'Moscow', '37'],\n",
       "   ['2', 'David', 'Tel-Aviv', '52'],\n",
       "   ['3', 'Jack', 'NewYork', '24']],\n",
       "  'types': [[int, str, str, int], [int, str, str, int], [int, str, str, int]]},\n",
       " 'text1': {'headers': ['ID', 'Name', 'City', 'Age'],\n",
       "  'data': [['1', 'John', 'Tomsk', '20'],\n",
       "   ['2', 'Sophie', 'Washington', '15'],\n",
       "   ['3', 'George', 'Tbilisi', '30'],\n",
       "   ['4', 'Ruslan', 'Erevan', '18'],\n",
       "   ['5', 'Emin', 'Baku', '32'],\n",
       "   ['6', 'Damir', 'Kazan', '19']],\n",
       "  'types': [[int, str, str, int],\n",
       "   [int, str, str, int],\n",
       "   [int, str, str, int],\n",
       "   [int, str, str, int],\n",
       "   [int, str, str, int],\n",
       "   [int, str, str, int]]}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "7ef36a27-f975-47eb-a58a-d9f89d99b8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_table(file, loaded_files=loaded_files) -> None:\n",
    "    file_name, _ = file_name_extension_checker(file)\n",
    "    if file_name not in loaded_files.keys():\n",
    "        loaded_files = load_table(file)\n",
    "\n",
    "    table_txt = tabulate(loaded_files[file_name]['data'], headers=loaded_files[file_name]['headers'], tablefmt='grid')\n",
    "        \n",
    "    print(table_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "caf95ccc-dbfc-4765-9a3e-4727cba1b4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+-------+\n",
      "|   ID | Name   | City     |   Age |\n",
      "+======+========+==========+=======+\n",
      "|    2 | David  | Tel-Aviv |    52 |\n",
      "+------+--------+----------+-------+\n",
      "|    3 | Jack   | NewYork  |    24 |\n",
      "+------+--------+----------+-------+\n"
     ]
    }
   ],
   "source": [
    "print_table('text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2157a795-8321-4180-90f1-9cc05bde7bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_by_number(file, start: int, stop: int, copy_table=False):\n",
    "    loaded_files = load_table(file)\n",
    "    file_name, ext = file_name_extension_checker(file=file)\n",
    "    new_table_list = []\n",
    "    \n",
    "    if copy_table == False:\n",
    "        if ext == 'txt':\n",
    "            with open(file, 'w', encoding='UTF-8') as file:\n",
    "                for i in range(start-1, stop):\n",
    "                    new_table_list.append(loaded_files[file_name]['data'][i])\n",
    "                new_table_dict = {file_name: {'headers': loaded_files[file_name]['headers'], 'data': new_table_list}}\n",
    "                file.writelines(f'{i} ' for i in new_table_dict[file_name]['headers'])\n",
    "                file.write('\\n')\n",
    "                for i in range(len(new_table_list)):\n",
    "                    file.writelines(f'{j} ' for j in new_table_dict[file_name]['data'][i])\n",
    "                    file.write('\\n')\n",
    "            print(f'Done. Check the file: {file_name}.{ext}')\n",
    "\n",
    "        elif ext == 'pkl':\n",
    "            with open(file, 'wb') as file:\n",
    "                for i in range(start-1, stop):\n",
    "                    new_table_list.append(loaded_files[file_name]['data'][i])\n",
    "                new_table_dict = {file_name: {'headers': loaded_files[file_name]['headers'], 'data': new_table_list}}\n",
    "                pickle.dump(new_table_dict[file_name], file)\n",
    "            print(f'Done. Check the file: {file_name}.{ext}')\n",
    "\n",
    "        elif ext == 'csv':\n",
    "            with open(file, 'w', newline='') as file:\n",
    "                new_table_list.append(loaded_files[file_name]['headers'])\n",
    "                for i in range(start-1, stop):\n",
    "                    new_table_list.append(loaded_files[file_name]['data'][i])\n",
    "                new_table_dict = {file_name: {'headers': loaded_files[file_name]['headers'], 'data': new_table_list[1:]}}\n",
    "                writer = csv.writer(file, delimiter=',')\n",
    "                writer.writerows(new_table_list)\n",
    "            print(f'Done. Check the file: {file_name}.{ext}')\n",
    "           \n",
    "    elif copy_table == True:\n",
    "        new_file = 'new_' + file_name + f'.{ext}'\n",
    "        new_file_name = 'new_' + file_name\n",
    "        \n",
    "        if ext == 'txt':\n",
    "            with open(file, 'r', encoding='UTF-8') as file:\n",
    "                for i in range(start-1, stop):\n",
    "                    new_table_list.append(loaded_files[file_name]['data'][i])\n",
    "                new_table_dict = {new_file_name: {'headers': loaded_files[file_name]['headers'], 'data': new_table_list}}\n",
    "            with open(new_file, 'w', encoding='UTF-8') as file:\n",
    "                file.writelines(f'{i} ' for i in new_table_dict[new_file_name]['headers'])\n",
    "                file.write('\\n')\n",
    "                for i in range(len(new_table_list)):\n",
    "                    file.writelines(f'{j} ' for j in new_table_dict[new_file_name]['data'][i])\n",
    "                    file.write('\\n')\n",
    "            print(f'Done. Check the file: {new_file}')\n",
    "\n",
    "        elif ext == 'pkl':\n",
    "            with open(file, 'rb') as file:\n",
    "                for i in range(start-1, stop):\n",
    "                    new_table_list.append(loaded_files[file_name]['data'][i])\n",
    "                new_table_dict = {new_file: {'headers': loaded_files[file_name]['headers'], 'data': new_table_list}}\n",
    "            with open(new_file, 'wb') as file:\n",
    "                pickle.dump(new_table_dict[new_file_name], file)\n",
    "            print(f'Done. Check the file: {new_file}')\n",
    "\n",
    "        elif ext == 'csv':\n",
    "            with open(file, 'r', newline='') as file:\n",
    "                new_table_list.append(loaded_files[file_name]['headers'])\n",
    "                for i in range(start-1, stop):\n",
    "                    new_table_list.append(loaded_files[file_name]['data'][i])\n",
    "                new_table_dict = {new_file_name: {'headers': loaded_files[file_name]['headers'], 'data': new_table_list[1:]}}\n",
    "            with open(new_file, 'w', newline='') as file:\n",
    "                writer = csv.writer(file, delimiter=',')\n",
    "                writer.writerows(new_table_list)\n",
    "            print(f'Done. Check the file: {new_file}')\n",
    "        \n",
    "    loaded_files.update(new_table_dict)   \n",
    "    save_table(loaded_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "150f629b-913c-404f-b2ad-cc212b69460f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Check the file: text.txt\n"
     ]
    }
   ],
   "source": [
    "get_rows_by_number('text.txt', 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "16bd3371-ecb5-441b-bc30-15e59b9c1ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+-------+\n",
      "|   ID | Name   | City     |   Age |\n",
      "+======+========+==========+=======+\n",
      "|    2 | David  | Tel-Aviv |    52 |\n",
      "+------+--------+----------+-------+\n",
      "|    3 | Jack   | NewYork  |    24 |\n",
      "+------+--------+----------+-------+\n"
     ]
    }
   ],
   "source": [
    "print_table('text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "e19fd79a-7642-4ac0-90f1-2179d6d7072a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Check the file: new_text.txt\n"
     ]
    }
   ],
   "source": [
    "get_rows_by_number('text.txt', 1, 2, copy_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "970a3162-7de9-4373-b1cb-83f229fdff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+-------+\n",
      "|   ID | Name   | City     |   Age |\n",
      "+======+========+==========+=======+\n",
      "|    2 | David  | Tel-Aviv |    52 |\n",
      "+------+--------+----------+-------+\n",
      "|    3 | Jack   | NewYork  |    24 |\n",
      "+------+--------+----------+-------+\n"
     ]
    }
   ],
   "source": [
    "print_table(\"new_text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "488ae86f-3c23-459b-9fb5-4b9ce7a0a78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_by_index(file, *val: int, copy_table=False):\n",
    "    loaded_files = load_table(file)\n",
    "    file_name, ext = file_name_extension_checker(file=file)\n",
    "    new_table_list = []\n",
    "    vals = list(val)\n",
    "    \n",
    "    if copy_table == False:\n",
    "        if ext == 'txt':\n",
    "            with open(file, 'w', encoding='UTF-8') as file:\n",
    "                for i in vals:\n",
    "                    new_table_list.append(loaded_files[file_name]['data'][i-1])\n",
    "                new_table_dict = {file_name: {'headers': loaded_files[file_name]['headers'], 'data': new_table_list}}\n",
    "                file.writelines(f'{i} ' for i in new_table_dict[file_name]['headers'])\n",
    "                file.write('\\n')\n",
    "                for i in range(len(new_table_list)):\n",
    "                    file.writelines(f'{j} ' for j in new_table_dict[file_name]['data'][i])\n",
    "                    file.write('\\n')\n",
    "            print(f'Done. Check the file: {file_name}.{ext}')\n",
    "\n",
    "        elif ext == 'pkl':\n",
    "            with open(file, 'wb') as file:\n",
    "                for i in vals:\n",
    "                    new_table_list.append(loaded_files[file_name]['data'][i-1])\n",
    "                new_table_dict = {file_name: {'headers': loaded_files[file_name]['headers'], 'data': new_table_list}}\n",
    "                pickle.dump(new_table_dict[file_name], file)\n",
    "            print(f'Done. Check the file: {file_name}.{ext}')\n",
    "\n",
    "        elif ext == 'csv':\n",
    "            with open(file, 'w', newline='') as file:\n",
    "                new_table_list.append(loaded_files[file_name]['headers'])\n",
    "                for i in vals:\n",
    "                    new_table_list.append(loaded_files[file_name]['data'][i-1])\n",
    "                new_table_dict = {file_name: {'headers': loaded_files[file_name]['headers'], 'data': new_table_list[1:]}}\n",
    "                writer = csv.writer(file, delimiter=',')\n",
    "                writer.writerows(new_table_list)\n",
    "            print(f'Done. Check the file: {file_name}.{ext}')\n",
    "           \n",
    "    elif copy_table == True:\n",
    "        new_file = 'new_' + file_name + f'.{ext}'\n",
    "        new_file_name = 'new_' + file_name\n",
    "        \n",
    "        if ext == 'txt':\n",
    "            with open(file, 'r', encoding='UTF-8') as file:\n",
    "                for i in range(len(vals)):\n",
    "                    new_table_list.append(loaded_files[file_name]['data'][i])\n",
    "                new_table_dict = {new_file_name: {'headers': loaded_files[file_name]['headers'], 'data': new_table_list}}\n",
    "            with open(new_file, 'w', encoding='UTF-8') as file:\n",
    "                file.writelines(f'{i} ' for i in new_table_dict[new_file_name]['headers'])\n",
    "                file.write('\\n')\n",
    "                for i in range(len(new_table_list)):\n",
    "                    file.writelines(f'{j} ' for j in new_table_dict[new_file_name]['data'][i])\n",
    "                    file.write('\\n')\n",
    "            print(f'Done. Check the file: {new_file}')\n",
    "\n",
    "        elif ext == 'pkl':\n",
    "            with open(file, 'rb') as file:\n",
    "                for i in vals:\n",
    "                    new_table_list.append(loaded_files[file_name]['data'][i-1])\n",
    "                new_table_dict = {new_file_name: {'headers': loaded_files[file_name]['headers'], 'data': new_table_list}}\n",
    "            with open(new_file, 'wb') as file:\n",
    "                pickle.dump(new_table_dict[new_file_name], file)\n",
    "            print(f'Done. Check the file: {new_file}')\n",
    "\n",
    "        elif ext == 'csv':\n",
    "            with open(file, 'r', newline='') as file:\n",
    "                new_table_list.append(loaded_files[file_name]['headers'])\n",
    "                for i in vals:\n",
    "                    new_table_list.append(loaded_files[file_name]['data'][i-1])\n",
    "                new_table_dict = {new_file_name: {'headers': loaded_files[file_name]['headers'], 'data': new_table_list[1:]}}\n",
    "            with open(new_file, 'w', newline='') as file:\n",
    "                writer = csv.writer(file, delimiter=',')\n",
    "                writer.writerows(new_table_list)\n",
    "            print(f'Done. Check the file: {new_file}')\n",
    "\n",
    "    loaded_files.update(new_table_dict)\n",
    "    save_table(loaded_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "8b0e6f89-5045-4433-9f6a-f6962d616655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Check the file: new_test.csv\n"
     ]
    }
   ],
   "source": [
    "get_rows_by_index('test.csv', 1, 3, copy_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6aca371e-24fb-4687-abc3-1c448ce24fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------------+\n",
      "|   ID | USER   | PASS            |\n",
      "+======+========+=================+\n",
      "|    1 | IVAN   | jhsfuga612      |\n",
      "+------+--------+-----------------+\n",
      "|    3 | ARTEM  | JHFIGAghHFJ6351 |\n",
      "+------+--------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "print_table(\"new_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "903a6951-48cb-4577-bc64-435f3d61f56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vals_append(vals, loaded_files, file_name):\n",
    "    vals.append([])\n",
    "    for i in range(len(loaded_files[file_name]['types'][0]) - 1):\n",
    "        vals.append([])\n",
    "    j = 0\n",
    "    while j != len(loaded_files[file_name]['types'][0]):\n",
    "        b = 0\n",
    "        vals_column = []\n",
    "        while b != len(loaded_files[file_name]['types']):\n",
    "            vals_column.append(loaded_files[file_name]['types'][b][j])\n",
    "            b+=1\n",
    "        vals[j] = vals_column\n",
    "        j += 1\n",
    "        \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5648178b-1479-4afe-bf5f-51a7281f2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_types(file, by_number=True) -> dict:\n",
    "    loaded_files = load_table(file)\n",
    "    file_name, ext = file_name_extension_checker(file=file)\n",
    "    vals = []\n",
    "    \n",
    "    if by_number == True:\n",
    "        keys = [i for i in range(len(loaded_files[file_name]['headers']))]\n",
    "        vals = vals_append(vals, loaded_files, file_name)\n",
    "    \n",
    "    elif by_number == False:\n",
    "        keys = [i for i in loaded_files[file_name]['headers']]\n",
    "        vals = vals_append(vals, loaded_files, file_name)\n",
    "        \n",
    "    types_dict = dict(zip(keys, vals))\n",
    "    return types_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "2796399b-6b96-400c-8f49-69d54363a02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [int, int, int], 1: [str, str, str], 2: [str, str, str]}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_column_types('test.csv', by_number=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "0d9caee8-90f0-4a62-8ffc-a51c83592c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': [int, int, int], 'USER': [str, str, str], 'PASS': [str, str, str]}"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_column_types('pikle.pkl', by_number=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "f3ff32c9-e969-4df1-b57a-bca4eebaecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_input(types_dict):\n",
    "    for i in list(types_dict.keys()):\n",
    "        set_type = str(f\"'{input('Set your column type: ')}'\")\n",
    "        if set_type != \"''\":\n",
    "            types_dict[i] = '<class ' + set_type + '>'\n",
    "        else:\n",
    "            types_dict[i] = None\n",
    "    return types_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "f9ba580b-2c8f-4d66-b3fe-9ef824fa67ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_column_types(file, by_number=True):\n",
    "    loaded_files = load_table(file)\n",
    "    file_name, ext = file_name_extension_checker(file=file)\n",
    "    \n",
    "    if by_number == True:\n",
    "        types_dict = get_column_types(file, by_number=True)\n",
    "        new_types_dict = dict_input(types_dict)\n",
    "            \n",
    "    elif by_number == False:\n",
    "        types_dict = get_column_types(file, by_number=False)\n",
    "        new_types_dict = dict_input(types_dict)\n",
    "    \n",
    "    print('Setting completed.')\n",
    "    return new_types_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "120cf066-e9e3-4f95-8d6e-7cfc3b7d321b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Set your column type:  \n",
      "Set your column type:  bool\n",
      "Set your column type:  float\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: None, 1: \"<class 'bool'>\", 2: \"<class 'float'>\"}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_column_types('text1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c005835c-2e15-43e9-8b6a-a4134e59b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(file, column=1) -> list:\n",
    "    loaded_files = load_table(file)\n",
    "    file_name, ext = file_name_extension_checker(file=file)\n",
    "    vals = []\n",
    "\n",
    "    if type(column) == int:\n",
    "        if len(loaded_files[file_name]['data']) == 1:\n",
    "            vals = get_value(file_name, column)\n",
    "\n",
    "        else:\n",
    "            if column > len(loaded_files[file_name]['headers']):\n",
    "                raise ValueError('The number of columns is less than the specified number.')\n",
    "            else:\n",
    "                for i in range(len(loaded_files[file_name]['data'])):\n",
    "                    vals.append((loaded_files[file_name]['data'][i][column-1]))\n",
    "\n",
    "    elif type(column) == str:\n",
    "        if len(loaded_files[file_name]['data']) == 1:\n",
    "            vals = get_value(file_name, column)\n",
    "\n",
    "        else:\n",
    "            if column not in loaded_files[file_name]['headers']:\n",
    "                raise ValueError('The specified column is missing.')\n",
    "            else:\n",
    "                index = loaded_files[file_name]['headers'].index(column)\n",
    "                for i in range(len(loaded_files[file_name]['data'])):\n",
    "                    vals.append((loaded_files[file_name]['data'][i][index]))\n",
    "\n",
    "    else:\n",
    "        raise TypeError('Only str or int type.')\n",
    "\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3591e82d-ac4e-40aa-aecb-90494d9ddf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IVAN', 'ARTEM']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_values('new_pikle.pkl', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "071d0620-fd57-4a22-94e8-8cfa780db3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(file_name, column=1):\n",
    "    loaded_files = load_table(file)\n",
    "    vals = []\n",
    "    if type(column) == int:\n",
    "        if column > len(loaded_files[file_name]['headers']):\n",
    "            raise ValueError('The number of columns is less than the specified number.')\n",
    "        else:\n",
    "            vals.append(loaded_files[file_name]['data'][0][column-1])\n",
    "\n",
    "    elif type(column) == str:\n",
    "        if column not in loaded_files[file_name]['headers']:\n",
    "            raise ValueError('The specified column is missing.')\n",
    "        else:\n",
    "            index = loaded_files[file_name]['headers'].index(column)\n",
    "            vals.append(loaded_files[file_name]['data'][0][index])\n",
    "\n",
    "    else:\n",
    "        raise TypeError('Only str or int type.')\n",
    "\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "919b37b9-4622-4db6-8952-274ed85ef072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_values(file, values: list, column=1):\n",
    "    file_name, ext = file_name_extension_checker(file=file)\n",
    "    loaded_files = load_table(file)\n",
    "    if len(loaded_files[file_name]['data']) == 1:\n",
    "        loaded_files = set_value(file, values[0], column)\n",
    "    else:\n",
    "        for i in range(len(values)):\n",
    "            loaded_files[file_name]['data'][i][column-1] = values[i]\n",
    "\n",
    "    loaded_files.update(loaded_files[file_name])\n",
    "    save_table(loaded_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "e68498b3-e040-4c0e-8fc3-6663cf93c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['Egor', 'Alex']\n",
    "set_values('text.txt', values, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "795a2350-ede1-446c-9539-6e14c1a7874c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+-------+\n",
      "|   ID | Name   | City     |   Age |\n",
      "+======+========+==========+=======+\n",
      "|    2 | Egor   | Tel-Aviv |    52 |\n",
      "+------+--------+----------+-------+\n",
      "|    3 | Alex   | NewYork  |    24 |\n",
      "+------+--------+----------+-------+\n"
     ]
    }
   ],
   "source": [
    "print_table('text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "edd69063-08de-4540-9be4-929572a78776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_value(file, value, column=1):\n",
    "    file_name, ext = file_name_extension_checker(file=file)    \n",
    "    loaded_files = load_table(file)\n",
    "    loaded_files[file_name]['data'][0][column-1] = value\n",
    "\n",
    "    return loaded_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "1cf6db7c-046b-49f5-a0e8-2329087690e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(file1, file2):\n",
    "    loaded_files = load_table(file1, file2)\n",
    "    file1_name, ext1 = file_name_extension_checker(file=file1)\n",
    "    file2_name, ex2 = file_name_extension_checker(file=file2)\n",
    "\n",
    "    new_table_name = file1_name + '_' + file2_name\n",
    "    new_headers_list = loaded_files[file1_name]['headers'] + loaded_files[file2_name]['headers']\n",
    "\n",
    "    new_data_list = []\n",
    "    for i in range(max(len(loaded_files[file1_name]['data']), len(loaded_files[file2_name]['data']))):\n",
    "        if len(loaded_files[file1_name]['data']) > len(loaded_files[file2_name]['data']):\n",
    "            diff = len(loaded_files[file1_name]['data']) - len(loaded_files[file2_name]['data'])\n",
    "            for j in range(diff):\n",
    "                loaded_files[file2_name]['data'].append(['-'])\n",
    "            for j in range(diff):\n",
    "                loaded_files[file2_name]['data'][j-diff] += ['-']*(len(loaded_files[file2_name]['headers'])-1)\n",
    "            new_data_list.append(loaded_files[file1_name]['data'][i] + loaded_files[file2_name]['data'][i])\n",
    "\n",
    "            for j in range(diff):\n",
    "                loaded_files[file2_name]['data'].pop(j-diff)\n",
    "        \n",
    "        elif len(loaded_files[file1_name]['data']) < len(loaded_files[file2_name]['data']):\n",
    "            diff = len(loaded_files[file2_name]['data']) - len(loaded_files[file1_name]['data'])\n",
    "            for j in range(diff):\n",
    "                loaded_files[file1_name]['data'].append(['-'])\n",
    "            for j in range(diff):\n",
    "                loaded_files[file1_name]['data'][j-diff] += ['-']*(len(loaded_files[file1_name]['headers'])-1)\n",
    "            new_data_list.append(loaded_files[file1_name]['data'][i] + loaded_files[file2_name]['data'][i])\n",
    "\n",
    "            for j in range(diff):\n",
    "                loaded_files[file1_name]['data'].pop(j-diff)\n",
    "        \n",
    "        else:\n",
    "            new_data_list.append(loaded_files[file1_name]['data'][i] + loaded_files[file2_name]['data'][i])\n",
    "        \n",
    "    new_table_dict = {new_table_name: {'headers': new_headers_list, 'data': new_data_list}}\n",
    "\n",
    "    print(f'Your table {new_table_name} is ready.')\n",
    "    loaded_files.update(new_table_dict)   \n",
    "    save_table(loaded_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "46b85d1d-a691-4bc4-90c4-c5fe3bdf1fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your table text_test is ready.\n"
     ]
    }
   ],
   "source": [
    "concat('text.txt', 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1b7af2e9-8d6b-418e-8e98-8c430f716030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+-------+------+--------+-----------------+\n",
      "| ID   | Name   | City     | Age   |   ID | USER   | PASS            |\n",
      "+======+========+==========+=======+======+========+=================+\n",
      "| 2    | David  | Tel-Aviv | 52    |    1 | IVAN   | jhsfuga612      |\n",
      "+------+--------+----------+-------+------+--------+-----------------+\n",
      "| 3    | Jack   | NewYork  | 24    |    2 | KOSTYA | EFSFGfj145nb    |\n",
      "+------+--------+----------+-------+------+--------+-----------------+\n",
      "| -    | -      | -        | -     |    3 | ARTEM  | JHFIGAghHFJ6351 |\n",
      "+------+--------+----------+-------+------+--------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "print_table('text_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
